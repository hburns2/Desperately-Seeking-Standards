{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desperately seeking standards: using text processing to save your eyesight (the code)\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "This dataset, pulled from university interlibrary loan records, consists of 5 columns and 38,231 rows (including column headers). The original dataset possessed far more columns, however, due to privacy and data cleaning reasons, excess columns were removed. The remaining columns are entitled \"Loan Title,\" \"Photo Journal Title,\" \"Photo Article Author,\" \"Photo Article Title,\" and \"Transaction Date.\" All columns contain textual information, save for the date column. Dates represented span from 2015-02-07 to 2019-05-08.\n",
    "\n",
    "\n",
    "## About the code\n",
    "\n",
    "Code was written using Jupyter Notebook version 6.2.0. It uses Python 3.7.4, pandas version 1.2.0, and the Python module ```re```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"ILL-deidentified-data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our ILL dataset, standards can be found in one of 3 columns: Photo Article Title, Loan Title, or Photo Journal Title. Using the pandas built-in function ```.findall```, we will be searching the dataset 3 times (once for each column) for any instances and variation of the word \"standard.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         []\n",
      "1        NaN\n",
      "2         []\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "38225     []\n",
      "38226    NaN\n",
      "38227    NaN\n",
      "38228    NaN\n",
      "38229    NaN\n",
      "Name: Photo Article Title, Length: 38230, dtype: object\n"
     ]
    }
   ],
   "source": [
    "standards1 = df['Photo Article Title'].str.findall('standard', flags=re.IGNORECASE)\n",
    "print(standards1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NaN\n",
      "1         []\n",
      "2        NaN\n",
      "3         []\n",
      "4         []\n",
      "        ... \n",
      "38225    NaN\n",
      "38226     []\n",
      "38227     []\n",
      "38228     []\n",
      "38229     []\n",
      "Name: Loan Title, Length: 38230, dtype: object\n"
     ]
    }
   ],
   "source": [
    "standards2 = df['Loan Title'].str.findall('standard', flags=re.IGNORECASE)\n",
    "print(standards2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         []\n",
      "1        NaN\n",
      "2         []\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "38225     []\n",
      "38226    NaN\n",
      "38227    NaN\n",
      "38228    NaN\n",
      "38229    NaN\n",
      "Name: Photo Journal Title, Length: 38230, dtype: object\n"
     ]
    }
   ],
   "source": [
    "standards3 = df['Photo Journal Title'].str.findall('standard', flags=re.IGNORECASE)\n",
    "print(standards3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a new dataset and exported that dataset to a new spreadsheet, changing the column header names so they're more easily distinguishable to the human eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [standards1, standards2, standards3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Article_Title\", \"Loan_Title\", \"Journal_Title\"]\n",
    "\n",
    "new_df = pd.concat(data, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"text-standards-ILL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this newly created spreadsheet, we manually went in and removed all instances of the characters \"[\" and \"]\". Once this is done, we read in the newly edited dataset once more, and then removed the unnecessary A column as well as all rows that only contain ```NaN``` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"text-standards-ILL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Article_Title', 'Loan_Title', 'Journal_Title'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Article_Title Loan_Title Journal_Title\n",
      "0               NaN        NaN           NaN\n",
      "1               NaN        NaN           NaN\n",
      "2               NaN        NaN           NaN\n",
      "3               NaN        NaN           NaN\n",
      "4               NaN        NaN           NaN\n",
      "...             ...        ...           ...\n",
      "38225           NaN        NaN           NaN\n",
      "38226           NaN        NaN           NaN\n",
      "38227           NaN        NaN           NaN\n",
      "38228           NaN        NaN           NaN\n",
      "38229           NaN        NaN           NaN\n",
      "\n",
      "[38230 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dropped_col = df2.drop(df2.columns[0], axis=1)\n",
    "print(dropped_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Article_Title Loan_Title Journal_Title\n",
      "135    Standard', 'Standard'        NaN           NaN\n",
      "853                Standard'        NaN           NaN\n",
      "888                standard'        NaN           NaN\n",
      "988                Standard'        NaN           NaN\n",
      "1370               Standard'        NaN           NaN\n",
      "...                      ...        ...           ...\n",
      "36990              standard'        NaN           NaN\n",
      "37067              standard'        NaN     Standard'\n",
      "37398                    NaN  Standard'           NaN\n",
      "37727                    NaN  Standard'           NaN\n",
      "37940              Standard'        NaN           NaN\n",
      "\n",
      "[169 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dropped_col.dropna(axis = 0, how = 'all', inplace = True)\n",
    "print(dropped_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_col.to_csv(\"text-cleaned_standards.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
