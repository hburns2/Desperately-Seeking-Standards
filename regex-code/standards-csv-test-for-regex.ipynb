{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desperately seeking standards: using text processing to save your eyesight (the code)\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "This dataset, pulled from university interlibrary loan records, consists of 5 columns and 38,231 rows (including column headers). The original dataset possessed far more columns, however, due to privacy and data cleaning reasons, excess columns were removed. The remaining columns are entitled \"Loan Title,\" \"Photo Journal Title,\" \"Photo Article Author,\" \"Photo Article Title,\" and \"Transaction Date.\" All columns contain textual information, save for the date column. Dates represented span from 2015-02-07 to 2019-05-08.\n",
    "\n",
    "\n",
    "## About the code\n",
    "\n",
    "Code was written using Jupyter Notebook version 6.2.0. It uses Python 3.7.4, pandas version 1.2.0, and the Python module ```re```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"ILL-deidentified-data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our ILL dataset, standards can be found in one of 3 columns: Photo Article Title, Loan Title, or Photo Journal Title. Using our established regular expression string, we will be searching the dataset 3 times (once for each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         []\n",
      "1        NaN\n",
      "2         []\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "38225     []\n",
      "38226    NaN\n",
      "38227    NaN\n",
      "38228    NaN\n",
      "38229    NaN\n",
      "Name: Photo Article Title, Length: 38230, dtype: object\n"
     ]
    }
   ],
   "source": [
    "standards1 = df['Photo Article Title'].str.findall(r'[A-Z]{2,}[^=%()\\n][A-Z]*[\\d]+[^=%()\\n]?[\\d]*')\n",
    "print(standards1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NaN\n",
      "1         []\n",
      "2        NaN\n",
      "3         []\n",
      "4         []\n",
      "        ... \n",
      "38225    NaN\n",
      "38226     []\n",
      "38227     []\n",
      "38228     []\n",
      "38229     []\n",
      "Name: Loan Title, Length: 38230, dtype: object\n"
     ]
    }
   ],
   "source": [
    "standards2 = df['Loan Title'].str.findall(r'[A-Z]{2,}[^=%()\\n][A-Z]*[\\d]+[^=%()\\n]?[\\d]*')\n",
    "print(standards2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         []\n",
      "1        NaN\n",
      "2         []\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "38225     []\n",
      "38226    NaN\n",
      "38227    NaN\n",
      "38228    NaN\n",
      "38229    NaN\n",
      "Name: Photo Journal Title, Length: 38230, dtype: object\n"
     ]
    }
   ],
   "source": [
    "standards3 = df['Photo Journal Title'].str.findall(r'[A-Z]{2,}[^=%()\\n][A-Z]*[\\d]+[^=%()\\n]?[\\d]*')\n",
    "print(standards3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a new dataset and exported that dataset to a new spreadsheet, changing the column header names so they're more easily distinguishable to the human eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [standards1, standards2, standards3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Article_Title\", \"Loan_Title\", \"Journal_Title\"]\n",
    "\n",
    "new_df = pd.concat(data, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"regex-standards-ILL.csv\") #then went into the spreadsheet and removed all instanced of [ and ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this newly created spreadsheet, we manually went in and removed all instances of the characters \"[\" and \"]\". Once this is done, we read in the newly edited dataset once more, and then removed the unnecessary A column as well as all rows that only contain ```NaN``` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"regex-standards-ILL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Article_Title', 'Loan_Title', 'Journal_Title'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Article_Title Loan_Title Journal_Title\n",
      "0               NaN        NaN           NaN\n",
      "1               NaN        NaN           NaN\n",
      "2               NaN        NaN           NaN\n",
      "3               NaN        NaN           NaN\n",
      "4               NaN        NaN           NaN\n",
      "...             ...        ...           ...\n",
      "38225           NaN        NaN           NaN\n",
      "38226           NaN        NaN           NaN\n",
      "38227           NaN        NaN           NaN\n",
      "38228           NaN        NaN           NaN\n",
      "38229           NaN        NaN           NaN\n",
      "\n",
      "[38230 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dropped_col = df2.drop(df2.columns[0], axis=1)\n",
    "print(dropped_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Article_Title  Loan_Title Journal_Title\n",
      "47              NaN  WQTC 2013'           NaN\n",
      "48              NaN  WQTC 2013'           NaN\n",
      "51              NaN         NaN       ACE 11'\n",
      "54              NaN         NaN       ACE 10'\n",
      "78          TREM2 '         NaN           NaN\n",
      "...             ...         ...           ...\n",
      "37653     IN 1874:'         NaN           NaN\n",
      "37935      CH3C6H4'         NaN           NaN\n",
      "38009           NaN      LOD2 '           NaN\n",
      "38179           NaN  ISO 527-1'           NaN\n",
      "38218   RTOG 94-06'         NaN           NaN\n",
      "\n",
      "[486 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dropped_col.dropna(axis = 0, how = 'all', inplace = True)\n",
    "print(dropped_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_col.to_csv(\"regex-cleaned_standards.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
